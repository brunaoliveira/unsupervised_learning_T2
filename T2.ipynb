{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bruna/.local/lib/python3.6/site-packages/sklearn/__init__.py'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__file__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/bruna/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-c192863e584b>\", line 19, in <module>\n",
      "    from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
      "ModuleNotFoundError: No module named 'sklearn.metrics'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bruna/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bruna/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/bruna/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/bruna/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/usr/lib/python3/dist-packages/py/_vendored_packages/apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"/usr/lib/python3/dist-packages/py/_vendored_packages/apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"/usr/lib/python3/dist-packages/py/_vendored_packages/apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"/usr/lib/python3/dist-packages/pytest.py\", line 13, in <module>\n",
      "    from _pytest.fixtures import fixture, yield_fixture\n",
      "  File \"/usr/lib/python3/dist-packages/_pytest/fixtures.py\", line 842, in <module>\n",
      "    class FixtureFunctionMarker(object):\n",
      "  File \"/usr/lib/python3/dist-packages/_pytest/fixtures.py\", line 844, in FixtureFunctionMarker\n",
      "    params = attr.ib(convert=attr.converters.optional(tuple))\n",
      "TypeError: attrib() got an unexpected keyword argument 'convert'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math\n",
    "import collections\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.spatial.distance import cosine\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "from pprint import pprint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção da Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEGA PATH DE TODAS IMAGENS E COLOCA NUM ARRAY\n",
    "all_paths = []\n",
    "classes = listdir('./natural_images_100/')\n",
    "\n",
    "for root, dirs, files in os.walk('./natural_images_100/'):\n",
    "    for d in dirs:\n",
    "        for f in listdir(root + d):\n",
    "            all_paths.append(root + d + '/' + f)\n",
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCA TDS IMAGENS EM UM ARRAY DE IMAGENS PIL 224x224\n",
    "all_images = np.empty(len(all_paths), dtype=object)\n",
    "for n in range(0, len(all_paths)):\n",
    "    all_images[n] = image.load_img(all_paths[n], target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(all_images_index):\n",
    "    img = all_images[all_images_index]\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros que vamos utilizar\n",
    "\n",
    "# Utilizar modelo pré-treinado no ImageNet\n",
    "weights = 'imagenet'\n",
    "\n",
    "# Utilizar a rede sem a camada final de classificação\n",
    "include_top = False\n",
    "\n",
    "# Indicamos que queremos um average pooling na última camada\n",
    "pooling = 'avg'\n",
    "\n",
    "# Shape de entrada.\n",
    "input_shape=(224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.applications.resnet.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "model = VGG16(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating to all features\n",
    "# SALVA ARRAY DE FEATURES EM UM GRANDE ARRAY PARA TDS FEATURES\n",
    "all_features = np.empty((len(all_images), model._nested_outputs.shape[1]))\n",
    "feature_list_np = []\n",
    "feature_list = []\n",
    "\n",
    "for i in range(len(all_images)):\n",
    "    x = image.img_to_array(all_images[i])\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    features = model.predict(x)\n",
    "    feature_list_np.append(np.array(features))\n",
    "    feature_list.append((np.array(features)).flatten())\n",
    "\n",
    "    for feature in features:\n",
    "        all_features[i] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(all_features))\n",
    "print(np.shape(all_features[0]))\n",
    "print()\n",
    "print(np.shape(feature_list))\n",
    "print(np.shape(feature_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printa features da primeira imagem\n",
    "len(all_features)\n",
    "pprint(all_features[0])\n",
    "for a in all_features:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando shape e tipo das features da prmeira imagem\n",
    "print(all_features[0].shape, features.dtype, '\\n')\n",
    "\n",
    "# Mostrando as features.\n",
    "pprint(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Aplicação de Algoritmos de Agrupamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# X = all_features\n",
    "df = pd.DataFrame(feature_list)\n",
    "kmedoids = KMedoids(n_clusters=len(classes), random_state=0).fit(df)\n",
    "print('Inércia do KMedoids: ', kmedoids.inertia_)\n",
    "# reduced_data = PCA(n_components=len(classes)).fit_transform(feature_list)\n",
    "# print(dir(reduced_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniBatchKmeans = MiniBatchKMeans(n_clusters=len(classes), random_state=0).fit(df)\n",
    "# miniBatchKmeans = miniBatchKmeans.partial_fit(all_features[0:200,:])\n",
    "# miniBatchKmeans = miniBatchKmeans.partial_fit(all_features[200:400,:])\n",
    "# miniBatchKmeans.cluster_centers_\n",
    "prediction = miniBatchKmeans.predict([all_features[0], all_features[722]]) \n",
    "\n",
    "print('Inércia do Mini Batch Kmeans: ', miniBatchKmeans.inertia_)\n",
    "print('Classes: ', classes)\n",
    "print('Prediction: ', prediction)\n",
    "# print_image(722)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "\n",
    "batch_size = 45\n",
    "# centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "n_clusters = len(centers)\n",
    "# X, labels_true = make_blobs(n_samples=3000, centers=centers, cluster_std=0.7)\n",
    "# X = feature_list\n",
    "X = all_features\n",
    "# X = np.array(feature_list)\n",
    "print(type(X))\n",
    "# #############################################################################\n",
    "# Compute clustering with Means\n",
    "\n",
    "k_means = KMeans(n_clusters=len(classes), random_state=0)\n",
    "t0 = time.time()\n",
    "k_means.fit(X)\n",
    "t_batch = time.time() - t0\n",
    "\n",
    "# #############################################################################\n",
    "# Compute clustering with MiniBatchKMeans\n",
    "\n",
    "mbk = MiniBatchKMeans(n_clusters=len(classes), batch_size=batch_size, random_state=0)\n",
    "t0 = time.time()\n",
    "mbk.fit(X)\n",
    "t_mini_batch = time.time() - t0\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "\n",
    "fig = plt.figure(figsize=(12, 3))\n",
    "fig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\n",
    "colors = ['black', 'magenta', 'orchid', 'darkorange', 'red', 'yellow', 'green', 'cyan']\n",
    "\n",
    "# We want to have the same colors for the same cluster from the\n",
    "# MiniBatchKMeans and the KMeans algorithm. Let's pair the cluster centers per\n",
    "# closest one.\n",
    "k_means_cluster_centers = np.sort(k_means.cluster_centers_, axis=0)\n",
    "mbk_means_cluster_centers = np.sort(mbk.cluster_centers_, axis=0)\n",
    "k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)\n",
    "mbk_means_labels = pairwise_distances_argmin(X, mbk_means_cluster_centers)\n",
    "order = pairwise_distances_argmin(k_means_cluster_centers, mbk_means_cluster_centers)\n",
    "\n",
    "# KMeans\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for k, col in zip(range(len(classes)), colors):\n",
    "    my_members = k_means_labels == k\n",
    "    cluster_center = k_means_cluster_centers[k]\n",
    "    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n",
    "    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=6)\n",
    "ax.set_title('KMeans')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "# #############################################################################\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "\n",
    "batch_size = 45\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "n_clusters = len(centers)\n",
    "X, labels_true = make_blobs(n_samples=3000, centers=centers, cluster_std=0.7)\n",
    "\n",
    "# #############################################################################\n",
    "# Compute clustering with Means\n",
    "\n",
    "k_means = KMeans(init='k-means++', n_clusters=3, n_init=10)\n",
    "t0 = time.time()\n",
    "k_means.fit(X)\n",
    "t_batch = time.time() - t0\n",
    "\n",
    "# #############################################################################\n",
    "# Compute clustering with MiniBatchKMeans\n",
    "\n",
    "mbk = MiniBatchKMeans(init='k-means++', n_clusters=3, batch_size=batch_size,\n",
    "                      n_init=10, max_no_improvement=10, verbose=0)\n",
    "t0 = time.time()\n",
    "mbk.fit(X)\n",
    "t_mini_batch = time.time() - t0\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "fig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\n",
    "colors = ['#4EACC5', '#FF9C34', '#4E9A06']\n",
    "\n",
    "# We want to have the same colors for the same cluster from the\n",
    "# MiniBatchKMeans and the KMeans algorithm. Let's pair the cluster centers per\n",
    "# closest one.\n",
    "k_means_cluster_centers = np.sort(k_means.cluster_centers_, axis=0)\n",
    "mbk_means_cluster_centers = np.sort(mbk.cluster_centers_, axis=0)\n",
    "k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)\n",
    "mbk_means_labels = pairwise_distances_argmin(X, mbk_means_cluster_centers)\n",
    "order = pairwise_distances_argmin(k_means_cluster_centers, mbk_means_cluster_centers)\n",
    "\n",
    "\n",
    "# KMeans\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = k_means_labels == k\n",
    "    cluster_center = k_means_cluster_centers[k]\n",
    "    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n",
    "    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=6)\n",
    "ax.set_title('KMeans')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "plt.text(-3.5, 1.8,  'train time: %.2fs\\ninertia: %f' % (t_batch, k_means.inertia_))\n",
    "\n",
    "# MiniBatchKMeans\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = mbk_means_labels == order[k]\n",
    "    cluster_center = mbk_means_cluster_centers[order[k]]\n",
    "    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n",
    "    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=6)\n",
    "ax.set_title('MiniBatchKMeans')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "plt.text(-3.5, 1.8, 'train time: %.2fs\\ninertia: %f' % (t_mini_batch, mbk.inertia_))\n",
    "\n",
    "# Initialise the different array to all False\n",
    "different = (mbk_means_labels == 4)\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "for k in range(n_clusters):\n",
    "    different += ((k_means_labels == k) != (mbk_means_labels == order[k]))\n",
    "\n",
    "identic = np.logical_not(different)\n",
    "ax.plot(X[identic, 0], X[identic, 1], 'w', markerfacecolor='#bbbbbb', marker='.')\n",
    "ax.plot(X[different, 0], X[different, 1], 'w', markerfacecolor='m', marker='.')\n",
    "ax.set_title('Difference')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=len(classes), random_state=0).fit(np.array(np.array(feature_list)))\n",
    "# dir(kmeans)\n",
    "print('Inércia do Kmeans: ', kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.datasets import load_nfl\n",
    "\n",
    "# X = all_features\n",
    "X = np.array(feature_list)\n",
    "km = KMeans(8, random_state=0)\n",
    "visualizer = SilhouetteVisualizer(km, colors='yellowbrick')\n",
    "\n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARA DUAS IMAGENS PARECIDAS PRA VALIDAR A AS FEATURES\n",
    "distance = cosine(feature_list[0], feature_list[2])\n",
    "print(distance)\n",
    "print_image(0)\n",
    "print_image(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KMeans(n_clusters=k, random_state=random_state, verbose=verbose)\n",
    "# data_copy = df.copy()\n",
    "# # data_copy.drop(columns='label', inplace=True)\n",
    "\n",
    "# kmeans.fit(data_copy)\n",
    "# data_copy['cluster_labels'] = kmeans.labels_\n",
    "# _ = sns.scatterplot(x='x', y='y', data=data_copy, hue='cluster_labels', palette='rainbow', legend=False)\n",
    "\n",
    "# centroids = kmeans.cluster_centers_\n",
    "# centroids_x = centroids[:,0]\n",
    "# centroids_y = centroids[:,1]\n",
    "\n",
    "# _ = plt.scatter(centroids_x, centroids_y, color='black', s=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans\tscipy.cluster.kmeans.kmeans\n",
    "# Hierarchical Cluster\tscipy.cluster.hierarchy.fcluster\n",
    "# DBSCAN\tsklearn.cluster.DBSCAN\n",
    "# Birch\tsklearn.cluster.Birch\n",
    "# K-Medoids Cluster\t\n",
    "# pyclust.KMedoids(Unknown reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "plt.figure()\n",
    "plt.clf()\n",
    "\n",
    "plt.suptitle(\"Comparing multiple K-Medoids metrics to K-Means and each other\", fontsize=14)\n",
    "\n",
    "\n",
    "selected_models = [\n",
    "    (KMedoids(metric=\"manhattan\", n_clusters=len(classes)), \"KMedoids (manhattan)\"),\n",
    "    (KMedoids(metric=\"euclidean\", n_clusters=len(classes)), \"KMedoids (euclidean)\"),\n",
    "    (KMedoids(metric=\"cosine\", n_clusters=len(classes)), \"KMedoids (cosine)\"),\n",
    "    (KMeans(n_clusters=num_classes), \"KMeans\"),\n",
    "]\n",
    "\n",
    "plot_rows = int(np.ceil(len(selected_models) / 2.0))\n",
    "plot_cols = 2\n",
    "\n",
    "for i, (model, description) in enumerate(selected_models):\n",
    "    # Obtain labels for each point in mesh. Use last trained model.\n",
    "    model.fit(reduced_data)\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.subplot(plot_cols, plot_rows, i + 1)\n",
    "    plt.imshow(\n",
    "        Z,\n",
    "        interpolation=\"nearest\",\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        cmap=plt.cm.Paired,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "\n",
    "    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2, alpha=0.3)\n",
    "    # Plot the centroids as a white X\n",
    "    centroids = model.cluster_centers_\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", s=169, linewidths=3, color=\"w\",zorder=10)\n",
    "    plt.title(description)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Avaliação do resultado dos agrupamentos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Externo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
